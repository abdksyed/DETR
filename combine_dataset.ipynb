{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import json\r\n",
    "import os\r\n",
    "from pathlib import Path\r\n",
    "import glob\r\n",
    "from copy import deepcopy\r\n",
    "import shutil\r\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "json_paths = []\r\n",
    "for i in glob.glob('./detr/datasets/Dataset/**', recursive=True):\r\n",
    "    file_path = Path(i)\r\n",
    "    if file_path.suffix == '.json':\r\n",
    "        json_paths.append(file_path)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "f = open(Path('./detr/datasets/Dataset/aac_blocks/annotations/aac_blocks.json'))\r\n",
    "initial_json = json.load(f)\r\n",
    "f.close()\r\n",
    "\r\n",
    "COMBINED_JSON = deepcopy(initial_json)\r\n",
    "IMAGE_ID = 1\r\n",
    "\r\n",
    "IMAGES = []\r\n",
    "ANNOTATIONS = []\r\n",
    "for json_path in json_paths:\r\n",
    "    f = open(json_path)\r\n",
    "    json_data = json.load(f)\r\n",
    "    f.close()\r\n",
    "    json_data_copy = deepcopy(json_data)\r\n",
    "\r\n",
    "    localid2globalid = {}\r\n",
    "    for image_det in json_data_copy['images']:\r\n",
    "        localid2globalid[image_det['id']] = IMAGE_ID\r\n",
    "        image_det['id'] = IMAGE_ID\r\n",
    "        IMAGE_ID += 1\r\n",
    "\r\n",
    "        image_det['file_name'] = json_path.parent.parent.name + '_____' + image_det['file_name']\r\n",
    "\r\n",
    "        IMAGES.append(image_det)\r\n",
    "\r\n",
    "    for ann_det in json_data_copy['annotations']:\r\n",
    "        ann_det['image_id'] = localid2globalid[ann_det['image_id']]\r\n",
    "        ann_det['file_name'] = json_path.parent.parent.name + '___' + ann_det['file_name']\r\n",
    "\r\n",
    "        ANNOTATIONS.append(ann_det)\r\n",
    "\r\n",
    "    \r\n",
    "\r\n",
    "COMBINED_JSON['images'] = IMAGES\r\n",
    "COMBINED_JSON['annotations'] = ANNOTATIONS\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "out_file = open('./detr/datasets/combined.json', \"w\")\r\n",
    "json.dump(COMBINED_JSON, out_file, indent = 4)\r\n",
    "out_file.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Segmentation JSON to BBox JSON"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "f = open(Path('./detr/datasets/combined.json'))\r\n",
    "json_data = json.load(f)\r\n",
    "f.close()\r\n",
    "\r\n",
    "json_data_bbox = deepcopy(json_data)\r\n",
    "\r\n",
    "annotations = []\r\n",
    "ANN_ID = 1\r\n",
    "for ann in json_data['annotations']:\r\n",
    "    for seg in ann['segments_info']:\r\n",
    "        obj_dic = deepcopy(seg)\r\n",
    "        obj_dic['id'] = ANN_ID\r\n",
    "        ANN_ID += 1\r\n",
    "        obj_dic['image_id'] = ann['image_id']\r\n",
    "        annotations.append(obj_dic)\r\n",
    "\r\n",
    "\r\n",
    "json_data_bbox['annotations'] = annotations\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "out_file = open('./detr/datasets/combined_bbox.json', \"w\")\r\n",
    "json.dump(json_data_bbox, out_file, indent = 4)\r\n",
    "out_file.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Test and Train JSONs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "f = open('./detr/datasets/combined_bbox.json')\r\n",
    "new_json_data = json.load(f)\r\n",
    "f.close()\r\n",
    "\r\n",
    "all_images = deepcopy(new_json_data['images'])\r\n",
    "\r\n",
    "train_images, test_images = train_test_split(all_images, test_size=0.1, random_state=42)\r\n",
    "\r\n",
    "\r\n",
    "actual_image2id = {'train': {}, 'test': {}}\r\n",
    "def new_ids(list_data, test_train):\r\n",
    "    global actual_image2id\r\n",
    "    new_id = 1\r\n",
    "    for data_point in list_data:\r\n",
    "        actual_image2id[test_train][data_point['id']] = new_id\r\n",
    "        data_point['id'] = new_id\r\n",
    "        new_id += 1\r\n",
    "    \r\n",
    "    return list_data\r\n",
    "\r\n",
    "train_data = new_ids(train_images, 'train')\r\n",
    "test_data = new_ids(test_images, 'test')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "len(train_data), len(test_data)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(9008, 1001)"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "train_json = deepcopy(new_json_data)\r\n",
    "test_json = deepcopy(new_json_data)\r\n",
    "\r\n",
    "train_json['images'] = train_data\r\n",
    "test_json['images'] = test_data\r\n",
    "\r\n",
    "train_annotations = []\r\n",
    "test_annotations = []\r\n",
    "\r\n",
    "for ann in deepcopy(new_json_data['annotations']):\r\n",
    "    if ann['image_id'] in  actual_image2id['train'].keys():\r\n",
    "        ann['image_id'] = actual_image2id['train'][ann['image_id']]\r\n",
    "        train_annotations.append(ann)\r\n",
    "\r\n",
    "    elif ann['image_id'] in  actual_image2id['test'].keys():\r\n",
    "        ann['image_id'] = actual_image2id['test'][ann['image_id']]\r\n",
    "        test_annotations.append(ann)\r\n",
    "        \r\n",
    "    else:\r\n",
    "        print('SOMETHING IS WRONG', ann)\r\n",
    "\r\n",
    "train_json['annotations'] = train_annotations\r\n",
    "test_json['annotations'] = test_annotations"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "out_file = open('./detr/datasets/combined_train.json', \"w\")\r\n",
    "json.dump(train_json, out_file, indent = 4)\r\n",
    "out_file.close()\r\n",
    "\r\n",
    "out_file = open('./detr/datasets/combined_test.json', \"w\")\r\n",
    "json.dump(test_json, out_file, indent = 4)\r\n",
    "out_file.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Making all Images in One"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "f = open('./detr/datasets/combined_bbox.json')\r\n",
    "final_json_data = json.load(f)\r\n",
    "f.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "copy_json = deepcopy(final_json_data)\r\n",
    "\r\n",
    "for image_det in copy_json['images']:\r\n",
    "    class_name, image_name = image_det['file_name'].split('_____')\r\n",
    "    from_path = f'detr/datasets/Dataset/{class_name}/images/{image_name}'\r\n",
    "    to_path = f\"detr/datasets/images/{image_det['file_name']}\"\r\n",
    "\r\n",
    "    shutil.copy(from_path, to_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "f = open('./detr/datasets/combined.json')\r\n",
    "final_json_data = json.load(f)\r\n",
    "f.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "copy_json = deepcopy(final_json_data)\r\n",
    "\r\n",
    "for image_det in copy_json['annotations']:\r\n",
    "    class_name, image_name = image_det['file_name'].split('_____')\r\n",
    "    from_path = f'detr/datasets/Dataset/{class_name}/annotations/{image_name}'\r\n",
    "    to_path = f\"detr/datasets/annotations/{image_det['file_name']}\"\r\n",
    "\r\n",
    "    shutil.copy(from_path, to_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "f = open('./detr/datasets/combined_test.json')\r\n",
    "final_json_data = json.load(f)\r\n",
    "f.close()\r\n",
    "\r\n",
    "copy_json = deepcopy(final_json_data)\r\n",
    "\r\n",
    "total_len = len(copy_json['images'])\r\n",
    "\r\n",
    "random_list = random.sample(copy_json['images'], 500)\r\n",
    "random_list = random.sample(random_list, 300)\r\n",
    "\r\n",
    "for image_det in random_list:\r\n",
    "    class_name, image_name = image_det['file_name'].split('_____')\r\n",
    "    from_path = f'detr/datasets/Dataset/{class_name}/images/{image_name}'\r\n",
    "    to_path = f\"detr/datasets/sample_test_images/{image_det['file_name']}\"\r\n",
    "\r\n",
    "    shutil.copy(from_path, to_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Same Train-Test Split for BBox Copied to Panoptic"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "f = open('./detr/datasets/combined.json')\r\n",
    "final_json_data = json.load(f)\r\n",
    "f.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "f = open('./detr/datasets/combined_train.json')\r\n",
    "bbox_json_train = json.load(f)\r\n",
    "f.close()\r\n",
    "\r\n",
    "f = open('./detr/datasets/combined_test.json')\r\n",
    "bbox_json_test = json.load(f)\r\n",
    "f.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_img2id = {}\r\n",
    "test_img2id = {}\r\n",
    "\r\n",
    "for image_det in bbox_json_train['images']:\r\n",
    "    img_name = image_det['file_name'].split('.')[:-1]\r\n",
    "    img_name = '.'.join(img_name)\r\n",
    "    train_img2id[img_name] = image_det['id']\r\n",
    "\r\n",
    "for image_det in bbox_json_test['images']:\r\n",
    "    img_name = image_det['file_name'].split('.')[:-1]\r\n",
    "    img_name = '.'.join(img_name)\r\n",
    "    test_img2id[img_name] = image_det['id']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "panoptic_train_json = deepcopy(final_json_data)\r\n",
    "panoptic_test_json = deepcopy(final_json_data)\r\n",
    "\r\n",
    "panoptic_train_json['images'] = bbox_json_train['images']\r\n",
    "panoptic_test_json['images'] = bbox_json_test['images']\r\n",
    "\r\n",
    "train_annotations = []\r\n",
    "test_annotations = []\r\n",
    "\r\n",
    "for ann in deepcopy(final_json_data['annotations']):\r\n",
    "    file_name = ann['file_name'].split('.')[:-1]\r\n",
    "    file_name = '.'.join(file_name)\r\n",
    "    if file_name in train_img2id.keys():\r\n",
    "        ann['image_id'] = train_img2id[file_name]\r\n",
    "        train_annotations.append(ann)\r\n",
    "\r\n",
    "    elif file_name in test_img2id.keys():\r\n",
    "        ann['image_id'] = test_img2id[file_name]\r\n",
    "        test_annotations.append(ann)\r\n",
    "        \r\n",
    "    else:\r\n",
    "        print('SOMETHING IS WRONG', ann)\r\n",
    "\r\n",
    "panoptic_train_json['annotations'] = train_annotations\r\n",
    "panoptic_test_json['annotations'] = test_annotations"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "out_file = open('./detr/datasets/panoptic_train.json', \"w\")\r\n",
    "json.dump(panoptic_train_json, out_file, indent = 4)\r\n",
    "out_file.close()\r\n",
    "\r\n",
    "out_file = open('./detr/datasets/panoptic_test.json', \"w\")\r\n",
    "json.dump(panoptic_test_json, out_file, indent = 4)\r\n",
    "out_file.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('deeplearning': conda)"
  },
  "interpreter": {
   "hash": "d77b49bd42968f5d71bb66190fe946614e1470f69bc14d8b2e10a94fbb7812e5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}